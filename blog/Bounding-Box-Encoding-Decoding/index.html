<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="twitter:image:src" content="https://levanliu.github.io/images/favicon/android-chrome-512x512.png"><meta name="referrer" content="no-referrer-when-downgrade"><title>Bounding Box Encoding and Decoding in Object Detection - Lei Mao&#039;s Log Book</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#3273dc"><meta name="application-name" content="Lei Mao&#039;s Log Book"><meta name="msapplication-TileImage" content="/images/favicon/android-chrome-192x192.png"><meta name="msapplication-TileColor" content="#3273dc"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Lei Mao&#039;s Log Book"><meta name="apple-mobile-web-app-status-bar-style" content="default"><link rel="apple-touch-icon" sizes="192x192" href="/images/favicon/android-chrome-192x192.png"><link rel="apple-touch-icon" sizes="512x512" href="/images/favicon/android-chrome-512x512.png"><link rel="apple-touch-icon" sizes="180x180" href="/images/favicon/apple-touch-icon.png"><link rel="apple-touch-icon" sizes="16x16" href="/images/favicon/favicon-16x16.png"><link rel="apple-touch-icon" sizes="32x32" href="/images/favicon/favicon-32x32.png"><meta name="description" content="Some Secret Recipes Hard to Find"><meta property="og:type" content="blog"><meta property="og:title" content="Bounding Box Encoding and Decoding in Object Detection"><meta property="og:url" content="https://levanliu.github.io/blog/Bounding-Box-Encoding-Decoding/"><meta property="og:site_name" content="Lei Mao&#039;s Log Book"><meta property="og:description" content="Some Secret Recipes Hard to Find"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://levanliu.github.io/images/favicon/android-chrome-512x512.png"><meta property="article:published_time" content="2019-04-08T07:00:00.000Z"><meta property="article:modified_time" content="2019-04-08T07:00:00.000Z"><meta property="article:author" content="Lei Mao"><meta property="article:tag" content="Computer Vision"><meta property="article:tag" content="Statistics"><meta property="article:tag" content="Object Detection"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://levanliu.github.io/images/favicon/android-chrome-512x512.png"><meta property="twitter:creator" content="@matchalevanliu"><meta property="twitter:site" content="Lei Mao&#039;s Log Book"><meta property="fb:admins" content="dukelevanliu"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://levanliu.github.io/blog/Bounding-Box-Encoding-Decoding/"},"headline":"Bounding Box Encoding and Decoding in Object Detection","image":["https://levanliu.github.io/images/favicon/android-chrome-512x512.png"],"datePublished":"2019-04-08T07:00:00.000Z","dateModified":"2019-04-08T07:00:00.000Z","author":{"@type":"Person","name":"Lei Mao"},"publisher":{"@type":"Organization","name":"Lei Mao's Log Book","logo":{"@type":"ImageObject","url":"https://levanliu.github.io/images/favicon/android-chrome-512x512.png"}},"description":"Some Secret Recipes Hard to Find"}</script><link rel="canonical" href="https://levanliu.github.io/blog/Bounding-Box-Encoding-Decoding/"><link rel="alternate" href="/atom.xml" title="Lei Mao&#039;s Log Book" type="application/atom+xml"><link rel="icon" href="/images/favicon/favicon.ico"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons/css/academicons.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=PT+Sans+Narrow:wght@400;700&amp;family=PT+Serif"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=G-EJY6FXZBCB" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'G-EJY6FXZBCB');</script><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><script src="//m.servedby-buysellads.com/monetization.custom.js"></script><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/images/favicon/android-chrome-512x512.png" alt="Lei Mao&#039;s Log Book" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Lei Mao&#039;s Log Book</a><a class="navbar-item" href="/curriculum">Curriculum</a><a class="navbar-item" href="/blog">Blog</a><a class="navbar-item" href="/article">Articles</a><a class="navbar-item" href="/project">Projects</a><a class="navbar-item" href="/publication">Publications</a><a class="navbar-item" href="/reading">Readings</a><a class="navbar-item" href="/life">Life</a><a class="navbar-item" href="/essay">Essay</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/faq">FAQs</a></div><div class="navbar-end"><a class="navbar-item night" id="night-nav" title="Switch Color Scheme" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/levanliu"><i class="fab fa-github"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="Gitter" href="https://gitter.im/levanliu/community"><i class="fab fa-gitter"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><div class="card-content"><center><div class="bsa-standard" id="carbon-ad-01"></div><script>            (function() {             if (typeof _bsa !== 'undefined' && _bsa) {                 _bsa.init('custom', 'CWYD65QY', 'placement:levanliugithubio-standard', {                     target: '#carbon-ad-01',                     template: `             <a href='##link##' class='native-banner' style='background: ##backgroundColor##' rel='sponsored noopener' target='_blank' title='##company## — ##tagline##'>                 <img class='native-img' width='125' src='##logo##' />                 <div class='native-main'>                     <div class='native-details' style='                             color: ##textColor##;                             border-left: solid 1px ##textColor##;                         '>                         <span class='native-company'>Sponsored by ##company##</span>                         <span class='native-desc'>##description##</span>                     </div>                     <span class='native-cta' style='                             color: ##ctaTextColor##;                             background-color: ##ctaBackgroundColor##;                         '>##callToAction##</span>                 </div>             </a>             `,                 });                 }             })();         </script></center></div></div><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-3" style="font-family: 'PT Sans Narrow', sans-serif">Bounding Box Encoding and Decoding in Object Detection</h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left" style="margin-bottom: 0.50rem"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2019-04-08T07:00:00.000Z" title="2019-04-08T07:00:00.000Z">04-08-2019</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="2019-04-08T07:00:00.000Z" title="2019-04-08T07:00:00.000Z">04-08-2019</time></span><span class="level-item"><i class="far fa-folder-open has-text-grey"></i> <a class="link-muted" href="/blog/">blog</a></span><span class="level-item"><i class="far fa-clock"></i> 16 minutes read (About 2335 words)</span><span class="level-item" id="busuanzi_container_page_pv"><i class="far fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"><i class="fa fa-spinner fa-spin"></i></span>&nbsp;visits</span></div></div><div class="content" style="margin-top: 1.0rem"><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>In modern object detection programs, the model usually has an object classifier and a bounding box regressor. The bounding box usually consists of four parameters. Intuitively they could be the center coordinates of the bounding box, width, and height of the bounding box. I remembered that in my very first object detection program of digit number localization in 2015, I was using such kind of naive bounding box and it worked reasonably well. Nowadays, the bounding box still consists of four parameters, but the four parameters usually have been encoded. Some encoding methods are obscure and are not publicly well discussed in research papers. In this blog post, we are going to look at some of these methods and talk about the motivations behind them.</p>
<h2 id="Bounding-Box-Regression"><a href="#Bounding-Box-Regression" class="headerlink" title="Bounding Box Regression"></a>Bounding Box Regression</h2><p>Most recently object detection programs have the concept of anchor boxes, also called prior boxes, which are pre-defined fix-sized bounding boxes on image input or feature map. The bounding box regressor, instead of predicting the bounding box location on the image, predicts the offset of the ground-truth/predicted bounding box to the anchor box. For example, if the anchor box representation is [0.2, 0.5, 0.1, 0.2], and the representation of the ground-truth box corresponding to the anchor box is [0.25, 0.55, 0.08, 0.25], the prediction target, which is the offset, should be [0.05, 0.05, -0.02, 0.05]. The object detection bounding box regressor is trying to learn how to predict this offset. If you have the prediction and the corresponding anchor box representation, you could easily calculate back to predicted bounding box representation. This step is also called decoding.</p>
<h2 id="Bounding-Box-Representation"><a href="#Bounding-Box-Representation" class="headerlink" title="Bounding Box Representation"></a>Bounding Box Representation</h2><p>The bounding box could be represented in many ways. Most intuitively, there are some ways as follows.</p>
<h3 id="Centroids-Representation"><a href="#Centroids-Representation" class="headerlink" title="Centroids Representation"></a>Centroids Representation</h3><p>A bounding box could be represented as [$x$, $y$, $w$, $h$], where $x$ and $y$ are the coordinates of the bounding box centroid, $w$ and $h$ are the width and height of the bounding box.</p>
<h3 id="Corners-Representation"><a href="#Corners-Representation" class="headerlink" title="Corners Representation"></a>Corners Representation</h3><p>A bounding box could also be represented as [$x_{\text{min}}$, $y_{\text{min}}$, $x_{\text{max}}$, $y_{\text{max}}$], where $x_{\text{min}}$ and $y_{\text{min}}$ are the coordinates of the bounding box bottom-left corner, $x_{\text{max}}$ and $y_{\text{max}}$ are the coordinates of the bounding box top-right corner.</p>
<h3 id="MinMax-Representation"><a href="#MinMax-Representation" class="headerlink" title="MinMax Representation"></a>MinMax Representation</h3><p>Similar to the corner representation, a bounding box could also be represented as [$x_{\text{min}}$, $x_{\text{max}}$, $y_{\text{min}}$, $y_{\text{max}}$], where $x_{\text{min}}$ and $x_{\text{max}}$ are the minimum and maximum of the $x$ coordinates, and $y_{\text{min}}$ and $y_{\text{max}}$ are the minimum and maximum of the $y$ coordinates. It is almost identical to the corner representation.</p>
<h2 id="Bounding-Box-Encoding"><a href="#Bounding-Box-Encoding" class="headerlink" title="Bounding Box Encoding"></a>Bounding Box Encoding</h2><p>The above bounding box representations are usually encoded as the final representation of the bounding box. </p>
<h3 id="Centroids-Representation-Encoding"><a href="#Centroids-Representation-Encoding" class="headerlink" title="Centroids Representation Encoding"></a>Centroids Representation Encoding</h3><p>The encoded representation of a ground-truth bounding box [$x_{\text{gt}}$, $y_{\text{gt}}$, $w_{\text{gt}}$, $h_{\text{gt}}$] with the corresponding anchor box [$x_{\text{anchor}}$, $y_{\text{anchor}}$, $w_{\text{anchor}}$, $h_{\text{anchor}}$] is [$x’$, $y’$, $w’$, $h’$], where</p>
<p>$$<br>\begin{gather}<br>x’ = \frac{x_{\text{gt}} - x_{\text{anchor}}}{w_{\text{anchor}}} \\<br>y’ = \frac{y_{\text{gt}} - y_{\text{anchor}}}{h_{\text{anchor}}} \\<br>w’ = \ln{\bigg[\frac{w_{\text{gt}}}{w_{\text{anchor}}}\bigg]} \\<br>h’ = \ln{\bigg[\frac{h_{\text{gt}}}{h_{\text{anchor}}}\bigg]} \\<br>\end{gather}<br>$$</p>
<h3 id="Corners-Representation-Encoding"><a href="#Corners-Representation-Encoding" class="headerlink" title="Corners Representation Encoding"></a>Corners Representation Encoding</h3><p>The encoded representation of a ground-truth bounding box [$x_{\text{min, gt}}$, $y_{\text{min, gt}}$, $x_{\text{max, gt}}$, $y_{\text{max, gt}}$] with the corresponding anchor box [$x_{\text{min, anchor}}$, $y_{\text{min, anchor}}$, $x_{\text{max, anchor}}$, $y_{\text{max, anchor}}$] is [$x_{\text{min}}’$, $y_{\text{min}}’$, $x_{\text{max}}’$, $y_{\text{max}}’$], where</p>
<p>$$<br>\begin{gather}<br>x_{\text{min}}’ = \frac{x_{\text{min, gt}} - x_{\text{min, anchor}}}{w_{\text{anchor}}} \\<br>y_{\text{min}}’ = \frac{y_{\text{min, gt}} - y_{\text{min, anchor}}}{h_{\text{anchor}}} \\<br>x_{\text{max}}’ = \frac{x_{\text{max, gt}} - x_{\text{max, anchor}}}{w_{\text{anchor}}} \\<br>y_{\text{max}}’ = \frac{y_{\text{max, gt}} - y_{\text{max, anchor}}}{h_{\text{anchor}}} \\<br>\end{gather}<br>$$</p>
<h3 id="MinMax-Representation-Encoding"><a href="#MinMax-Representation-Encoding" class="headerlink" title="MinMax Representation Encoding"></a>MinMax Representation Encoding</h3><p>Similarly, the encoded representation of a ground-truth bounding box [$x_{\text{min, gt}}$, $x_{\text{max, gt}}$, $y_{\text{min, gt}}$, $y_{\text{max, gt}}$] with the corresponding anchor box [$x_{\text{min, anchor}}$, $x_{\text{max, anchor}}$, $y_{\text{min, anchor}}$, $y_{\text{max, anchor}}$] is [$x_{\text{min}}’$, $x_{\text{max}}’$, $y_{\text{min}}’$, $y_{\text{max}}’$], where</p>
<p>$$<br>\begin{gather}<br>x_{\text{min}}’ = \frac{x_{\text{min, gt}} - x_{\text{min, anchor}}}{w_{\text{anchor}}} \\<br>x_{\text{max}}’ = \frac{x_{\text{max, gt}} - x_{\text{max, anchor}}}{w_{\text{anchor}}} \\<br>y_{\text{min}}’ = \frac{y_{\text{min, gt}} - y_{\text{min, anchor}}}{h_{\text{anchor}}} \\<br>y_{\text{max}}’ = \frac{y_{\text{max, gt}} - y_{\text{max, anchor}}}{h_{\text{anchor}}} \\<br>\end{gather}<br>$$</p>
<h3 id="Representation-Encoding-With-Variance"><a href="#Representation-Encoding-With-Variance" class="headerlink" title="Representation Encoding With Variance"></a>Representation Encoding With Variance</h3><p>The above encoding methods are usually well documented in the papers such as the Faster R-CNN paper. However, when you start to read the code of object detection models, you will often start to see an “unexpected” input “variance”, such as [0.1, 0.1, 0.2, 0.2] where 0.1, 0.1, 0.2, 0.2 are for $x$, $y$, $w$, $h$ respectively, in the encoding functions, which was never mentioned in the papers. This variance input is extremely misleading. I have to admit that it took me a while to understand how it works and it is actually very simple. It should not be described that obscure in the code.</p>
<p>In bounding box encoding with variance, based on the bounding box encoding method described above, you will often see in the code from some thousand-star GitHub repositories, such as this <a target="_blank" rel="noopener" href="https://github.com/pierluigiferrari/ssd_keras/blob/master/ssd_encoder_decoder/ssd_input_encoder.py#L396">one</a>, that each encoded representation is further divided by their corresponding “variance”. For example, in centroid representation encoding with variance,</p>
<p>$$<br>\begin{gather}<br>x’’ = x’ / \sigma^2_{x} = \frac{x_{\text{gt}} - x_{\text{anchor}}}{w_{\text{anchor}}} / \sigma^2_{x}\\<br>y’’ = y’ / \sigma^2_{y} = \frac{y_{\text{gt}} - y_{\text{anchor}}}{h_{\text{anchor}}} / \sigma^2_{y} \\<br>w’’ = w’ / \sigma^2_{w} = \ln{\bigg[\frac{w_{\text{gt}}}{w_{\text{anchor}}}\bigg]} / \sigma^2_{w} \\<br>h’’ = h’ / \sigma^2_{h} = \ln{\bigg[\frac{h_{\text{gt}}}{h_{\text{anchor}}}\bigg]} / \sigma^2_{h} \\<br>\end{gather}<br>$$</p>
<p>where you will often see variance $\sigma_{x}^2 = 0.1$, $\sigma_{y}^2 = 0.1$, $\sigma_{w}^2 = 0.2$, $\sigma_{h}^2 = 0.2$. Although they have probably implemented the model correctly, but the way described this encoding method is often wrong and misleading, and nobody knows how those variance numbers were obtained. It also should be noted that expression $\sigma^2_{x}$ is wrong in their code comment because a random variable should not be expressed using a small letter.</p>
<p>In my opinion, it is actually a process of standard normalization instead of “encoding with variance”. The users first calculate the ground-truth bounding box representations according to the “Bounding Box Encoding” chapter I described above. With such many encoded ground-truth bounding box representations, you could always calculate the mean and variance of each representation. To achieve better machine learning accuracy, you would like to further normalize the representations by</p>
<p>$$<br>x’’ = \frac{x’-\mu_{X’}}{\sigma_{X’}}<br>$$</p>
<p>where $\mu_{x}$ is the mean of variable $X$ and $\sigma_{X’}$ is the standard deviation of variable $X’$. In that way, if the encoded bounding box $X’$ follows some Gaussian distribution, after normalization, the distribution would become standard normal distribution with a mean of 0 and variance of 1. This will be ideal for machine learning predictions.</p>
<p>In bounding box regression, $\mu_{X’} \approx 0$ in practice. Therefore we could normalize the representations by </p>
<p>$$<br>x’’ = \frac{x’}{\sigma_{X’}}<br>$$</p>
<p>So “divided by variance” is actually wrong! It should be divided by the standard deviation. If [0.1, 0.1, 0.2, 0.2] are really variance, the centroid representation encoding with variance should be</p>
<p>$$<br>\begin{gather}<br>x’’ = x’ / \sigma^2_{x} = \frac{x_{\text{gt}} - x_{\text{anchor}}}{w_{\text{anchor}}} / \sigma_{X’}\\<br>y’’ = y’ / \sigma^2_{y} = \frac{y_{\text{gt}} - y_{\text{anchor}}}{h_{\text{anchor}}} / \sigma_{Y’} \\<br>w’’ = w’ / \sigma^2_{w} = \ln{\bigg[\frac{w_{\text{gt}}}{w_{\text{anchor}}}\bigg]} / \sigma_{W’} \\<br>h’’ = h’ / \sigma^2_{h} = \ln{\bigg[\frac{h_{\text{gt}}}{h_{\text{anchor}}}\bigg]} / \sigma_{H’} \\<br>\end{gather}<br>$$</p>
<p>where $\sigma_{X’} = \sqrt{0.1}$, $\sigma_{Y’} = \sqrt{0.1}$, $\sigma_{W’} = \sqrt{0.2}$, $\sigma_{H’} = \sqrt{0.2}$</p>
<p>More concretely, the bounding box representation encoding with variance should be as follows.</p>
<h3 id="Centroids-Representation-Encoding-With-Variance"><a href="#Centroids-Representation-Encoding-With-Variance" class="headerlink" title="Centroids Representation Encoding With Variance"></a>Centroids Representation Encoding With Variance</h3><p>The encoded representation of a ground-truth bounding box [$x_{\text{gt}}$, $y_{\text{gt}}$, $w_{\text{gt}}$, $h_{\text{gt}}$] with the corresponding anchor box [$x_{\text{anchor}}$, $y_{\text{anchor}}$, $w_{\text{anchor}}$, $h_{\text{anchor}}$] is [$x’’$, $y’’$, $w’’$, $h’’$], where</p>
<p>$$<br>\begin{gather}<br>x’’ = x’ / \sigma_{X’}\\<br>y’’ = x’ / \sigma_{Y’}\\<br>w’’ = w’ / \sigma_{W’} \\<br>h’’ = h’ / \sigma_{H’} \\<br>\end{gather}<br>$$</p>
<p>and the standard deviations were calculated from the centroids representation encodings without variance [$x’$, $y’$, $w’$, $h’$] in the training dataset.</p>
<h3 id="Corners-Representation-Encoding-With-Variance"><a href="#Corners-Representation-Encoding-With-Variance" class="headerlink" title="Corners Representation Encoding With Variance"></a>Corners Representation Encoding With Variance</h3><p>The encoded representation of a ground-truth bounding box [$x_{\text{min, gt}}$, $y_{\text{min, gt}}$, $x_{\text{max, gt}}$, $y_{\text{max, gt}}$] with the corresponding anchor box [$x_{\text{min, anchor}}$, $y_{\text{min, anchor}}$, $x_{\text{max, anchor}}$, $y_{\text{max, anchor}}$] is [$x_{\text{min}}’’$, $y_{\text{min}}’’$, $x_{\text{max}}’’$, $y_{\text{max}}’’$], where</p>
<p>$$<br>\begin{gather}<br>x_{\text{min}}’’ = x_{\text{min}}’ / \sigma_{X_{\text{min}}’}\\<br>y_{\text{min}}’’ = y_{\text{min}}’ / \sigma_{Y_{\text{min}}’}\\<br>x_{\text{max}}’’ = x_{\text{max}}’ / \sigma_{X_{\text{max}}’}\\<br>y_{\text{max}}’’ = y_{\text{max}}’ / \sigma_{Y_{\text{min}}’} \\<br>\end{gather}<br>$$</p>
<p>and the standard deviations were calculated from the centroids representation encodings without variance [$x_{\text{min}}’$, $y_{\text{min}}’$, $x_{\text{max}}’$, $y_{\text{max}}’$] in the training dataset.</p>
<h3 id="MinMax-Representation-Encoding-With-Variance"><a href="#MinMax-Representation-Encoding-With-Variance" class="headerlink" title="MinMax Representation Encoding With Variance"></a>MinMax Representation Encoding With Variance</h3><p>The encoded representation of a ground-truth bounding box [$x_{\text{min, gt}}$, $x_{\text{max, gt}}$, $y_{\text{min, gt}}$, $y_{\text{max, gt}}$] with the corresponding anchor box [$x_{\text{min, anchor}}$, $y_{\text{min, anchor}}$, $x_{\text{max, anchor}}$, $y_{\text{max, anchor}}$] is [$x_{\text{min}}’’$, $x_{\text{max}}’’$, $y_{\text{min}}’’$, $y_{\text{max}}’’$], where</p>
<p>$$<br>\begin{gather}<br>x_{\text{min}}’’ = x_{\text{min}}’ / \sigma_{X_{\text{min}}’}\\<br>x_{\text{max}}’’ = x_{\text{max}}’ / \sigma_{X_{\text{max}}’}\\<br>y_{\text{min}}’’ = y_{\text{min}}’ / \sigma_{Y_{\text{min}}’}\\<br>y_{\text{max}}’’ = y_{\text{max}}’ / \sigma_{Y_{\text{min}}’} \\<br>\end{gather}<br>$$</p>
<p>and the standard deviations were calculated from the centroids representation encodings without variance [$x_{\text{min}}’$, $x_{\text{max}}’$, $y_{\text{min}}’$, $y_{\text{max}}’$] in the training dataset.</p>
<h2 id="Bounding-Box-Decoding"><a href="#Bounding-Box-Decoding" class="headerlink" title="Bounding Box Decoding"></a>Bounding Box Decoding</h2><p>Once you know how the bounding box encoding works, it is very easy to do bounding box decoding during inference.</p>
<h3 id="Centroids-Representation-Decoding-With-Variance"><a href="#Centroids-Representation-Decoding-With-Variance" class="headerlink" title="Centroids Representation Decoding With Variance"></a>Centroids Representation Decoding With Variance</h3><p>The decoded representation of a predicted bounding box [$x_{\text{pred}}’’$, $y_{\text{pred}}’’$, $w_{\text{pred}}’’$, $h_{\text{pred}}’’$] with the corresponding anchor box [$x_{\text{anchor}}$, $y_{\text{anchor}}$, $w_{\text{anchor}}$, $h_{\text{anchor}}$] and pre-calculated variances [$\sigma_{X’}^2$, $\sigma_{Y’}^2$, $\sigma_{W’}^2$, $\sigma_{H’}^2$] is [$x_{\text{pred}}$, $y_{\text{pred}}$, $w_{\text{pred}}$, $h_{\text{pred}}$], where</p>
<p>$$<br>\begin{gather}<br>x_{\text{pred}} = x_{\text{pred}}’’ \sigma_{X’} w_{\text{anchor}} + x_{\text{anchor}} \\<br>y_{\text{pred}} = y_{\text{pred}}’’ \sigma_{Y’} h_{\text{anchor}} + y_{\text{anchor}} \\<br>w_{\text{pred}} = \exp({w_{\text{pred}}’’ \sigma_{W’}}) w_{\text{anchor}} \\<br>h_{\text{pred}} = \exp({h_{\text{pred}}’’ \sigma_{H’}}) h_{\text{anchor}} \\<br>\end{gather}<br>$$</p>
<h3 id="Corners-Representation-Decoding-With-Variance"><a href="#Corners-Representation-Decoding-With-Variance" class="headerlink" title="Corners Representation Decoding With Variance"></a>Corners Representation Decoding With Variance</h3><p>The decoded representation of a predicted bounding box [$x_{\text{min, pred}}’’$, $y_{\text{min, pred}}’’$, $x_{\text{max, pred}}’’$, $y_{\text{max, pred}}’’$] with the corresponding anchor box [$x_{\text{min, anchor}}$, $y_{\text{min, anchor}}$, $x_{\text{max, anchor}}$, $y_{\text{max, anchor}}$] and pre-calculated variances [$\sigma_{X_{\text{min}}’}^2$, $\sigma_{Y_{\text{min}}’}^2$, $\sigma_{X_{\text{max}}’}^2$, $\sigma_{X_{\text{max}}’}^2$] is [$x_{\text{min, pred}}$, $y_{\text{min, pred}}$, $x_{\text{max, pred}}$, $y_{\text{max, pred}}$], where</p>
<p>$$<br>\begin{gather}<br>x_{\text{min, pred}} = x_{\text{min, pred}}’’ \sigma_{X_{\text{min}}’} w_{\text{anchor}} + x_{\text{min, anchor}} \\<br>y_{\text{min, pred}} = y_{\text{min, pred}}’’ \sigma_{Y_{\text{min}}’} h_{\text{anchor}} + y_{\text{min, anchor}} \\<br>x_{\text{max, pred}} = x_{\text{max, pred}}’’ \sigma_{X_{\text{max}}’} w_{\text{anchor}} + x_{\text{max, anchor}} \\<br>y_{\text{max, pred}} = y_{\text{max, pred}}’’ \sigma_{Y_{\text{max}}’} h_{\text{anchor}} + y_{\text{max, anchor}} \\<br>\end{gather}<br>$$</p>
<h3 id="MinMax-Representation-Decoding-With-Variance"><a href="#MinMax-Representation-Decoding-With-Variance" class="headerlink" title="MinMax Representation Decoding With Variance"></a>MinMax Representation Decoding With Variance</h3><p>The decoded representation of a predicted bounding box [$x_{\text{min, pred}}’’$, $x_{\text{max, pred}}’’$, $y_{\text{min, pred}}’’$, $y_{\text{max, pred}}’’$] with the corresponding anchor box [$x_{\text{min, anchor}}$, $x_{\text{max, anchor}}$, $y_{\text{min, anchor}}$, $y_{\text{max, anchor}}$] and pre-calculated variances [$\sigma_{X_{\text{min}}’}^2$, $\sigma_{X_{\text{max}}’}^2$, $\sigma_{Y_{\text{min}}’}^2$, $\sigma_{X_{\text{max}}’}^2$] is [$x_{\text{min, pred}}$, $x_{\text{max, pred}}$, $y_{\text{min, pred}}$, $y_{\text{max, pred}}$], where</p>
<p>$$<br>\begin{gather}<br>x_{\text{min, pred}} = x_{\text{min, pred}}’’ \sigma_{X_{\text{min}}’} w_{\text{anchor}} + x_{\text{min, anchor}} \\<br>x_{\text{max, pred}} = x_{\text{max, pred}}’’ \sigma_{X_{\text{max}}’} w_{\text{anchor}} + x_{\text{max, anchor}} \\<br>y_{\text{min, pred}} = y_{\text{min, pred}}’’ \sigma_{Y_{\text{min}}’} h_{\text{anchor}} + y_{\text{min, anchor}} \\<br>y_{\text{max, pred}} = y_{\text{max, pred}}’’ \sigma_{Y_{\text{max}}’} h_{\text{anchor}} + y_{\text{max, anchor}} \\<br>\end{gather}<br>$$</p>
<h2 id="Final-Remarks"><a href="#Final-Remarks" class="headerlink" title="Final Remarks"></a>Final Remarks</h2><p>Even if the normalization was conducted using the incorrect standard deviation, the normal distribution after “incorrect” normalization will still be normal. The only difference is that the variance of the distribution after normalization will not be 1. But the mean will still be roughly zero. So the effect of normalization using the incorrect standard deviation is small or even negligible, and that is why those implementation GitHub is conceptually incorrect but still works well in practice.</p>
<p>It is very funny to see the error propagates because of the lack of good documentation.</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>Bounding Box Encoding and Decoding in Object Detection</p><p><a href="https://levanliu.github.io/blog/Bounding-Box-Encoding-Decoding/">https://levanliu.github.io/blog/Bounding-Box-Encoding-Decoding/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Lei Mao</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>04-08-2019</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>04-08-2019</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <div><a class="link-muted" rel="tag" href="/tags/Computer-Vision/">Computer Vision,</a> </div><div><a class="link-muted" rel="tag" href="/tags/Statistics/">Statistics,</a> </div><div><a class="link-muted" rel="tag" href="/tags/Object-Detection/">Object Detection </a> </div></div></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=61b5930d440224001908310c&amp;product=inline-share-buttons" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered has-text-weight-normal">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button donate" data-type="paypal" onclick="document.getElementById(&#039;paypal-donate-form&#039;).submit()"><span class="icon is-small"><i class="fab fa-paypal"></i></span><span>Paypal</span></a><form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_blank" rel="noopener" id="paypal-donate-form"><input type="hidden" name="cmd" value="_donations"><input type="hidden" name="business" value="SSVSLEH4X85LU"><input type="hidden" name="currency_code" value="USD"></form><a class="button donate" href="https://www.buymeacoffee.com/levanliu" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>Buy me a coffee</span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/blog/YOLOs/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Introduction to YOLOs</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/blog/PC-Build-Gaming-Deep-Learning/"><span class="level-item">Powerful Gaming and Deep Learning PC Build</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card" id="comment-card"><div class="card-content"><h3 class="title is-5">Comments</h3><div class="comment-block"><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://levanliu.github.io/blog/Bounding-Box-Encoding-Decoding/';
            this.page.identifier = '/blog/Bounding-Box-Encoding-Decoding/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'levanliu-github-io' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/author_images/Lei-Bio-Medium.jpg" alt="Lei Mao"></figure><p class="title is-size-4 is-block" style="line-height:inherit;margin-bottom:0.30rem;">Lei Mao</p><p class="is-block" style="white-space: pre-line; font-style: italic; margin-bottom: 0.50rem; font-size: 0.8em">Artificial Intelligence
Machine Learning
Computer Science
</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Santa Clara, California</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">733</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">7</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">453</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/levanliu" target="_blank" rel="noopener"><i class="fab fa-github"></i>  Follow</a> <a class="level-item button is-primary is-rounded" href="https://github.com/sponsors/levanliu" target="_blank" rel="noopener"><i class="fas fa-heart"></i>  Sponsor</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/levanliu"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/matchalevanliu"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="LinkedIn" href="https://www.linkedin.com/in/lei-mao/"><i class="fab fa-linkedin"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="mailto:dukelevanliu@gmail.com"><i class="fas fa-envelope-square"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="G.Scholar" href="https://scholar.google.com/citations?user=R2VUf7YAAAAJ"><i class="ai ai-google-scholar-square"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Introduction"><span class="level-left"><span class="level-item">1</span><span class="level-item">Introduction</span></span></a></li><li><a class="level is-mobile" href="#Bounding-Box-Regression"><span class="level-left"><span class="level-item">2</span><span class="level-item">Bounding Box Regression</span></span></a></li><li><a class="level is-mobile" href="#Bounding-Box-Representation"><span class="level-left"><span class="level-item">3</span><span class="level-item">Bounding Box Representation</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Centroids-Representation"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">Centroids Representation</span></span></a></li><li><a class="level is-mobile" href="#Corners-Representation"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">Corners Representation</span></span></a></li><li><a class="level is-mobile" href="#MinMax-Representation"><span class="level-left"><span class="level-item">3.3</span><span class="level-item">MinMax Representation</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Bounding-Box-Encoding"><span class="level-left"><span class="level-item">4</span><span class="level-item">Bounding Box Encoding</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Centroids-Representation-Encoding"><span class="level-left"><span class="level-item">4.1</span><span class="level-item">Centroids Representation Encoding</span></span></a></li><li><a class="level is-mobile" href="#Corners-Representation-Encoding"><span class="level-left"><span class="level-item">4.2</span><span class="level-item">Corners Representation Encoding</span></span></a></li><li><a class="level is-mobile" href="#MinMax-Representation-Encoding"><span class="level-left"><span class="level-item">4.3</span><span class="level-item">MinMax Representation Encoding</span></span></a></li><li><a class="level is-mobile" href="#Representation-Encoding-With-Variance"><span class="level-left"><span class="level-item">4.4</span><span class="level-item">Representation Encoding With Variance</span></span></a></li><li><a class="level is-mobile" href="#Centroids-Representation-Encoding-With-Variance"><span class="level-left"><span class="level-item">4.5</span><span class="level-item">Centroids Representation Encoding With Variance</span></span></a></li><li><a class="level is-mobile" href="#Corners-Representation-Encoding-With-Variance"><span class="level-left"><span class="level-item">4.6</span><span class="level-item">Corners Representation Encoding With Variance</span></span></a></li><li><a class="level is-mobile" href="#MinMax-Representation-Encoding-With-Variance"><span class="level-left"><span class="level-item">4.7</span><span class="level-item">MinMax Representation Encoding With Variance</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Bounding-Box-Decoding"><span class="level-left"><span class="level-item">5</span><span class="level-item">Bounding Box Decoding</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Centroids-Representation-Decoding-With-Variance"><span class="level-left"><span class="level-item">5.1</span><span class="level-item">Centroids Representation Decoding With Variance</span></span></a></li><li><a class="level is-mobile" href="#Corners-Representation-Decoding-With-Variance"><span class="level-left"><span class="level-item">5.2</span><span class="level-item">Corners Representation Decoding With Variance</span></span></a></li><li><a class="level is-mobile" href="#MinMax-Representation-Decoding-With-Variance"><span class="level-left"><span class="level-item">5.3</span><span class="level-item">MinMax Representation Decoding With Variance</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Final-Remarks"><span class="level-left"><span class="level-item">6</span><span class="level-item">Final Remarks</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget"><div class="g-ads-x"><div class="card-content"><div class="menu"><h3 class="menu-label">Advertisement</h3></div><br><center><script async type="text/javascript" src="//cdn.carbonads.com/carbon.js?serve=CWYDCK3L&amp;placement=levanliugithubio" id="_carbonads_js"></script></center></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/images/favicon/android-chrome-512x512.png" alt="Lei Mao&#039;s Log Book" height="28"></a><p class="is-size-7"><span>&copy; 2017-2024 Lei Mao</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Site UV: <span id="busuanzi_value_site_uv"><i class="fa fa-spinner fa-spin"></i></span></span> <span id="busuanzi_container_site_pv">Site PV: <span id="busuanzi_value_site_pv"><i class="fa fa-spinner fa-spin"></i></span></span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="GitHub" href="https://github.com/levanliu"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/javascript" id="MathJax-script" async>MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      },
      chtml: {
        matchFontHeight: false
      }
    };</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js"></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><script src="/js/night.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>