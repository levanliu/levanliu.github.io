<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="twitter:image:src" content="https://leimao.github.io/images/favicon/android-chrome-512x512.png"><meta name="referrer" content="no-referrer-when-downgrade"><title>PyTorch Leaf Tensor - Lei Mao&#039;s Log Book</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#3273dc"><meta name="application-name" content="Lei Mao&#039;s Log Book"><meta name="msapplication-TileImage" content="/images/favicon/android-chrome-192x192.png"><meta name="msapplication-TileColor" content="#3273dc"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Lei Mao&#039;s Log Book"><meta name="apple-mobile-web-app-status-bar-style" content="default"><link rel="apple-touch-icon" sizes="192x192" href="/images/favicon/android-chrome-192x192.png"><link rel="apple-touch-icon" sizes="512x512" href="/images/favicon/android-chrome-512x512.png"><link rel="apple-touch-icon" sizes="180x180" href="/images/favicon/apple-touch-icon.png"><link rel="apple-touch-icon" sizes="16x16" href="/images/favicon/favicon-16x16.png"><link rel="apple-touch-icon" sizes="32x32" href="/images/favicon/favicon-32x32.png"><meta name="description" content="Understanding PyTorch Leaf Tensor"><meta property="og:type" content="blog"><meta property="og:title" content="PyTorch Leaf Tensor"><meta property="og:url" content="https://leimao.github.io/blog/PyTorch-Leaf-Tensor/"><meta property="og:site_name" content="Lei Mao&#039;s Log Book"><meta property="og:description" content="Understanding PyTorch Leaf Tensor"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://leimao.github.io/images/blog/2023-06-19-PyTorch-Leaf-Tensor/dag.svg"><meta property="article:published_time" content="2023-06-19T07:00:00.000Z"><meta property="article:modified_time" content="2023-06-19T07:00:00.000Z"><meta property="article:author" content="Lei Mao"><meta property="article:tag" content="Deep Learning"><meta property="article:tag" content="PyTorch"><meta property="article:tag" content="Graph Algorithm"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://leimao.github.io/images/blog/2023-06-19-PyTorch-Leaf-Tensor/dag.svg"><meta property="twitter:creator" content="@matchaleimao"><meta property="twitter:site" content="Lei Mao&#039;s Log Book"><meta property="fb:admins" content="dukeleimao"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://leimao.github.io/blog/PyTorch-Leaf-Tensor/"},"headline":"PyTorch Leaf Tensor","image":[],"datePublished":"2023-06-19T07:00:00.000Z","dateModified":"2023-06-19T07:00:00.000Z","author":{"@type":"Person","name":"Lei Mao"},"publisher":{"@type":"Organization","name":"Lei Mao's Log Book","logo":{"@type":"ImageObject","url":"https://leimao.github.io/images/favicon/android-chrome-512x512.png"}},"description":"Understanding PyTorch Leaf Tensor"}</script><link rel="canonical" href="https://leimao.github.io/blog/PyTorch-Leaf-Tensor/"><link rel="alternate" href="/atom.xml" title="Lei Mao&#039;s Log Book" type="application/atom+xml"><link rel="icon" href="/images/favicon/favicon.ico"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons/css/academicons.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=PT+Sans+Narrow:wght@400;700&amp;family=PT+Serif"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=G-EJY6FXZBCB" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'G-EJY6FXZBCB');</script><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><script src="//m.servedby-buysellads.com/monetization.custom.js"></script><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/images/favicon/android-chrome-512x512.png" alt="Lei Mao&#039;s Log Book" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Lei Mao&#039;s Log Book</a><a class="navbar-item" href="/curriculum">Curriculum</a><a class="navbar-item" href="/blog">Blog</a><a class="navbar-item" href="/article">Articles</a><a class="navbar-item" href="/project">Projects</a><a class="navbar-item" href="/publication">Publications</a><a class="navbar-item" href="/reading">Readings</a><a class="navbar-item" href="/life">Life</a><a class="navbar-item" href="/essay">Essay</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/faq">FAQs</a></div><div class="navbar-end"><a class="navbar-item night" id="night-nav" title="Switch Color Scheme" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/leimao"><i class="fab fa-github"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="Gitter" href="https://gitter.im/leimao/community"><i class="fab fa-gitter"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><div class="card-content"><center><div class="bsa-standard" id="carbon-ad-01"></div><script>            (function() {             if (typeof _bsa !== 'undefined' && _bsa) {                 _bsa.init('custom', 'CWYD65QY', 'placement:leimaogithubio-standard', {                     target: '#carbon-ad-01',                     template: `             <a href='##link##' class='native-banner' style='background: ##backgroundColor##' rel='sponsored noopener' target='_blank' title='##company## — ##tagline##'>                 <img class='native-img' width='125' src='##logo##' />                 <div class='native-main'>                     <div class='native-details' style='                             color: ##textColor##;                             border-left: solid 1px ##textColor##;                         '>                         <span class='native-company'>Sponsored by ##company##</span>                         <span class='native-desc'>##description##</span>                     </div>                     <span class='native-cta' style='                             color: ##ctaTextColor##;                             background-color: ##ctaBackgroundColor##;                         '>##callToAction##</span>                 </div>             </a>             `,                 });                 }             })();         </script></center></div></div><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-3" style="font-family: 'PT Sans Narrow', sans-serif">PyTorch Leaf Tensor</h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left" style="margin-bottom: 0.50rem"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2023-06-19T07:00:00.000Z" title="2023-06-19T07:00:00.000Z">06-19-2023</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="2023-06-19T07:00:00.000Z" title="2023-06-19T07:00:00.000Z">06-19-2023</time></span><span class="level-item"><i class="far fa-folder-open has-text-grey"></i> <a class="link-muted" href="/blog/">blog</a></span><span class="level-item"><i class="far fa-clock"></i> 10 minutes read (About 1502 words)</span><span class="level-item" id="busuanzi_container_page_pv"><i class="far fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"><i class="fa fa-spinner fa-spin"></i></span>&nbsp;visits</span></div></div><div class="content" style="margin-top: 1.0rem"><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>PyTorch leaf tensor is a concept that is sometimes confusing to the users who are not familiar with the PyTorch’s automatic differentiation engine <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/autograd.html"><code>torch.autograd</code></a>.</p>
<p>In this blog post, I would like to quickly discuss the PyTorch leaf tensor concept from the perspective of mathematics without going into too much implementation detail.</p>
<h2 id="PyTorch-Leaf-Tensor"><a href="#PyTorch-Leaf-Tensor" class="headerlink" title="PyTorch Leaf Tensor"></a>PyTorch Leaf Tensor</h2><p>Depending on whether a PyTorch tensor requires gradient and whether a PyTorch tensor is explicitly created by the user, there are four categories of PyTorch tensors. Each tensor has attributes of whether it is a leaf tensor and whether the gradient will be populated for the tensor which are determined by whether the PyTorch tensor requires gradient and whether the PyTorch tensor is explicitly created by the user.</p>
<table>
<thead>
<tr>
<th align="center">Requires Grad</th>
<th align="center">User Created</th>
<th align="center">Is Leaf</th>
<th align="center">Grad Populated</th>
</tr>
</thead>
<tbody><tr>
<td align="center">true</td>
<td align="center">true</td>
<td align="center">true</td>
<td align="center">true</td>
</tr>
<tr>
<td align="center">true</td>
<td align="center">false</td>
<td align="center">false</td>
<td align="center">false</td>
</tr>
<tr>
<td align="center">false</td>
<td align="center">true</td>
<td align="center">true</td>
<td align="center">false</td>
</tr>
<tr>
<td align="center">false</td>
<td align="center">false</td>
<td align="center">true</td>
<td align="center">false</td>
</tr>
</tbody></table>
<p>Here, “Requires Grad” is the <code>requires_grad</code> attribute of a <code>torch.Tensor</code> indicating whether it is a constant or variable; “User Created” is true means that a <code>torch.Tensor</code> is not the result of an operation and so the <code>grad_fn</code> attribute of the <code>torch.Tensor</code> is <code>None</code>; “Is Leaf” is true means that a <code>torch.Tensor</code> is a leaf node in a <code>torch.autograd</code> directed acyclic graph (DAG) which only consists of a root (tensor) node, many leaf (tensor) nodes, and many intermediate (backward function call) nodes; “Grad Populated” is true means that the gradient with respect to a <code>torch.Tensor</code> will be saved in the tensor object (for optimization) so that the <code>grad</code> attribute of the <code>torch.Tensor</code> will not be <code>None</code> after a backward pass.</p>
<h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><p>In addition to the <a target="_blank" rel="noopener" href="https://pytorch.org/docs/1.13/generated/torch.Tensor.is_leaf.html#torch.Tensor.is_leaf">examples</a> from the PyTorch documentation which are rather confusing, we have a more concrete example here illustrating the role of leaf node in <code>torch.autograd</code>.</p>
<figure class="highlight python"><figcaption><span>leaf_tensor.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">print_tensor_attributes</span>(<span class="params">tensor: torch.Tensor</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;requires_grad: <span class="subst">&#123;tensor.requires_grad&#125;</span>, &quot;</span></span><br><span class="line">          <span class="string">f&quot;grad_fn: <span class="subst">&#123;tensor.grad_fn <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>&#125;</span>, &quot;</span></span><br><span class="line">          <span class="string">f&quot;is_leaf: <span class="subst">&#123;tensor.is_leaf&#125;</span>, &quot;</span></span><br><span class="line">          <span class="string">f&quot;grad: <span class="subst">&#123;tensor.grad <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line"></span><br><span class="line">    cuda_device = torch.device(<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line">    variable_tensor_cpu = torch.tensor([<span class="number">2.</span>, <span class="number">3.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">    variable_tensor_cuda = variable_tensor_cpu.to(cuda_device)</span><br><span class="line">    constant_tensor_cuda = torch.tensor([<span class="number">6.</span>, <span class="number">4.</span>],</span><br><span class="line">                                        requires_grad=<span class="literal">False</span>,</span><br><span class="line">                                        device=cuda_device)</span><br><span class="line">    loss = torch.<span class="built_in">sum</span>((constant_tensor_cuda - variable_tensor_cuda)**<span class="number">2</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Before Backward&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;variable_tensor_cpu&quot;</span>)</span><br><span class="line">    print_tensor_attributes(tensor=variable_tensor_cpu)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;variable_tensor_cuda&quot;</span>)</span><br><span class="line">    print_tensor_attributes(tensor=variable_tensor_cuda)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;constant_tensor_cuda&quot;</span>)</span><br><span class="line">    print_tensor_attributes(tensor=constant_tensor_cuda)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;loss&quot;</span>)</span><br><span class="line">    print_tensor_attributes(tensor=loss)</span><br><span class="line">    loss.backward()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-&quot;</span> * <span class="number">65</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;After Backward&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;variable_tensor_cpu&quot;</span>)</span><br><span class="line">    print_tensor_attributes(tensor=variable_tensor_cpu)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;variable_tensor_cuda&quot;</span>)</span><br><span class="line">    print_tensor_attributes(tensor=variable_tensor_cuda)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;constant_tensor_cuda&quot;</span>)</span><br><span class="line">    print_tensor_attributes(tensor=constant_tensor_cuda)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;loss&quot;</span>)</span><br><span class="line">    print_tensor_attributes(tensor=loss)</span><br></pre></td></tr></table></figure>


<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ python3 leaf_tensor.py </span><br><span class="line">Before Backward</span><br><span class="line">variable_tensor_cpu</span><br><span class="line">requires_grad: True, grad_fn: False, is_leaf: True, grad: False</span><br><span class="line">variable_tensor_cuda</span><br><span class="line">requires_grad: True, grad_fn: True, is_leaf: False, grad: False</span><br><span class="line">constant_tensor_cuda</span><br><span class="line">requires_grad: False, grad_fn: False, is_leaf: True, grad: False</span><br><span class="line">loss</span><br><span class="line">requires_grad: True, grad_fn: True, is_leaf: False, grad: False</span><br><span class="line">-----------------------------------------------------------------</span><br><span class="line">After Backward</span><br><span class="line">variable_tensor_cpu</span><br><span class="line">requires_grad: True, grad_fn: False, is_leaf: True, grad: True</span><br><span class="line">variable_tensor_cuda</span><br><span class="line">requires_grad: True, grad_fn: True, is_leaf: False, grad: False</span><br><span class="line">constant_tensor_cuda</span><br><span class="line">requires_grad: False, grad_fn: False, is_leaf: True, grad: False</span><br><span class="line">loss</span><br><span class="line">requires_grad: True, grad_fn: True, is_leaf: False, grad: False</span><br></pre></td></tr></table></figure>

<p>In some scenarios, the user would expect that the variable tensor <code>variable_tensor_cuda</code> would have <code>grad</code> after the backward pass so that it can be optimized during the neural network training. However, we could see that the <code>variable_tensor_cuda.grad</code> is <code>None</code> whereas the <code>variable_tensor_cpu</code> tensor has <code>grad</code>. This means the <code>variable_tensor_cpu</code> is the actually the variable for optimization. After the optimization is performed after the backward pass, the <code>variable_tensor_cuda</code> value will not be the same as the <code>variable_tensor_cpu</code> until the next forward pass is performed.</p>
<p>In fact, there is a warning when the user tries to access the <code>.grad</code> attribute of a non-leaf tensor which by default has no <code>.grad</code> attribute.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">leaf.py:6: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won<span class="string">&#x27;t be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /opt/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:480.)</span></span><br><span class="line"><span class="string">  print(f&quot;requires_grad: &#123;tensor.requires_grad&#125;, &quot;</span></span><br></pre></td></tr></table></figure>

<p>We could also visualize the DAG using a third party library <code>torchviz</code>. The <code>torchviz</code> library could be installed using the following command.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt update</span><br><span class="line">$ sudo apt install -y graphviz</span><br><span class="line">$ pip install torchviz</span><br></pre></td></tr></table></figure>

<p>The <code>torch.autograd</code> DAG is built as the Python script is executed. <code>torchviz</code> can visualize the DAG from a root tensor which is the <code>loss</code> tensor in our example.</p>
<figure class="highlight python"><figcaption><span>leaf_tensor_dag.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchviz <span class="keyword">import</span> make_dot</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">print_tensor_attributes</span>(<span class="params">tensor: torch.Tensor</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;requires_grad: <span class="subst">&#123;tensor.requires_grad&#125;</span>, &quot;</span></span><br><span class="line">          <span class="string">f&quot;grad_fn: <span class="subst">&#123;tensor.grad_fn <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>&#125;</span>, &quot;</span></span><br><span class="line">          <span class="string">f&quot;is_leaf: <span class="subst">&#123;tensor.is_leaf&#125;</span>, &quot;</span></span><br><span class="line">          <span class="string">f&quot;grad: <span class="subst">&#123;tensor.grad <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line"></span><br><span class="line">    cuda_device = torch.device(<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line">    variable_tensor_cpu = torch.tensor([<span class="number">2.</span>, <span class="number">3.</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">    variable_tensor_cuda = variable_tensor_cpu.to(cuda_device)</span><br><span class="line">    constant_tensor_cuda = torch.tensor([<span class="number">6.</span>, <span class="number">4.</span>],</span><br><span class="line">                                        requires_grad=<span class="literal">False</span>,</span><br><span class="line">                                        device=cuda_device)</span><br><span class="line">    loss = torch.<span class="built_in">sum</span>((constant_tensor_cuda - variable_tensor_cuda)**<span class="number">2</span>)</span><br><span class="line">    make_dot(loss).render(<span class="string">&quot;dag&quot;</span>, <span class="built_in">format</span>=<span class="string">&quot;svg&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>Notice that the DAG visualized using <code>torchviz</code> will not display the leaf node that does not require grad.</p>
<img src="/images/blog/2023-06-19-PyTorch-Leaf-Tensor/dag.svg" class="box px-0 py-0 ml-auto mr-auto" width="180" title="PyTorch Autograd DAG" alt="PyTorch Autograd DAG">
<br>

<p>The blue box in the DAG diagram, although having no tensor name, is the leaf tensor <code>variable_tensor_cpu</code> in our program.</p>
<h2 id="FAQ"><a href="#FAQ" class="headerlink" title="FAQ"></a>FAQ</h2><h3 id="Why-grad-is-not-populated-for-a-tensor-that-requires-grad-but-is-not-a-leaf-node"><a href="#Why-grad-is-not-populated-for-a-tensor-that-requires-grad-but-is-not-a-leaf-node" class="headerlink" title="Why grad is not populated for a tensor that requires grad but is not a leaf node?"></a>Why grad is not populated for a tensor that requires grad but is not a leaf node?</h3><p>Conventionally, only leaf tensors, usually model parameters to be trained, deserves grad. All the non-leaf tensors, such as the intermediate activation tensors, do not deserve grad. Why would we need to keep a grad for the activation tensors? Even if we keep the grad in the activation tensor and apply the grad to the activation tensor values in the optimization, those values will be overwritten in the next forward pass. So populating grad for non-leaf tensors is usually a waste of memory and computation.</p>
<p>However, in some “rare” use cases, the user would need the grad for non-leaf tensors, and PyTorch has the API <code>torch.Tensor.retain_grad()</code> for that. But usually it’s not making sense and is an indication of problematic implementation.</p>
<!-- 
## BBBBBBBBBBB


Conventionally, only leaf tensors, usually model parameters to be trained, deserves grad. All the non-leaf tensors, such as the intermediate activation tensors, do not deserve grad. (Why would you need to keep a grad for the activation tensors? Even if you apply grad to the activation tensor values in the optimization, those values will be overwritten in the next forward pass)
[5:40 PM]
However, in some rare use cases, the user would need the grad for non-leaf tensors, and PyTorch has the API for that. But usually it's not making sense.


For example, 
>>> b = torch.rand(10, requires_grad=True).cuda()
>>> b.is_leaf
False

The user might feed this b as an input to the nn.Module and wish the backward propagation and optimization can tune the value. But it would actually not do as the user expected, since cuda() is part of the computation graph and it is not a leaf tensor and there is no grad for it. The true leaf tensor in the graph, which is torch.rand(10, requires_grad=True) has been destroyed via garbage collection and is no longer accessible by the user.
So in this case, the user can do either
a = torch.rand(10, requires_grad=True)
b = a.cuda()

feed b to nn.Module and observe the changes in a since a is the leaf tensor.
or just do
b = torch.rand(10, requires_grad=True, device="cuda")
grad populated basically means the .grad attribute of a tensor will be filled during the backward pass.
 -->


<!-- 




Transformer input token embeddings training 
-->


<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html">PyTorch Autograd Tutorial</a></li>
<li><a target="_blank" rel="noopener" href="https://pytorch.org/docs/1.13/generated/torch.Tensor.is_leaf.html#torch.Tensor.is_leaf">PyTorch <code>is_leaf</code></a></li>
</ul>
</div><div class="article-licensing box"><div class="licensing-title"><p>PyTorch Leaf Tensor</p><p><a href="https://leimao.github.io/blog/PyTorch-Leaf-Tensor/">https://leimao.github.io/blog/PyTorch-Leaf-Tensor/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Lei Mao</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>06-19-2023</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>06-19-2023</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <div><a class="link-muted" rel="tag" href="/tags/Deep-Learning/">Deep Learning,</a> </div><div><a class="link-muted" rel="tag" href="/tags/PyTorch/">PyTorch,</a> </div><div><a class="link-muted" rel="tag" href="/tags/Graph-Algorithm/">Graph Algorithm </a> </div></div></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=61b5930d440224001908310c&amp;product=inline-share-buttons" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered has-text-weight-normal">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button donate" data-type="paypal" onclick="document.getElementById(&#039;paypal-donate-form&#039;).submit()"><span class="icon is-small"><i class="fab fa-paypal"></i></span><span>Paypal</span></a><form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_blank" rel="noopener" id="paypal-donate-form"><input type="hidden" name="cmd" value="_donations"><input type="hidden" name="business" value="SSVSLEH4X85LU"><input type="hidden" name="currency_code" value="USD"></form><a class="button donate" href="https://www.buymeacoffee.com/leimao" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>Buy me a coffee</span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/essay/%E5%A7%8B%E7%A5%96%E9%B8%9F-Arc&#039;teryx-Aerios-FL-2-Mid-GTX/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Arc&#039;teryx Aerios FL 2 Mid GTX 非专业评测</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/essay/%E5%87%BA%E5%85%A5%E5%A2%83%E7%AE%A1%E7%90%86%E5%B1%80%E9%99%90%E5%88%B6%E5%87%BA%E5%85%A5%E5%A2%83%E8%AF%88%E9%AA%97%E7%94%B5%E8%AF%9D/"><span class="level-item">出入境管理局限制出入境诈骗电话</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card" id="comment-card"><div class="card-content"><h3 class="title is-5">Comments</h3><div class="comment-block"><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://leimao.github.io/blog/PyTorch-Leaf-Tensor/';
            this.page.identifier = '/blog/PyTorch-Leaf-Tensor/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'leimao-github-io' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/author_images/Lei-Bio-Medium.jpg" alt="Lei Mao"></figure><p class="title is-size-4 is-block" style="line-height:inherit;margin-bottom:0.30rem;">Lei Mao</p><p class="is-block" style="white-space: pre-line; font-style: italic; margin-bottom: 0.50rem; font-size: 0.8em">Artificial Intelligence
Machine Learning
Computer Science
</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Santa Clara, California</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">733</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">7</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">453</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/leimao" target="_blank" rel="noopener"><i class="fab fa-github"></i>  Follow</a> <a class="level-item button is-primary is-rounded" href="https://github.com/sponsors/leimao" target="_blank" rel="noopener"><i class="fas fa-heart"></i>  Sponsor</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/leimao"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/matchaleimao"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="LinkedIn" href="https://www.linkedin.com/in/lei-mao/"><i class="fab fa-linkedin"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="mailto:dukeleimao@gmail.com"><i class="fas fa-envelope-square"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="G.Scholar" href="https://scholar.google.com/citations?user=R2VUf7YAAAAJ"><i class="ai ai-google-scholar-square"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Introduction"><span class="level-left"><span class="level-item">1</span><span class="level-item">Introduction</span></span></a></li><li><a class="level is-mobile" href="#PyTorch-Leaf-Tensor"><span class="level-left"><span class="level-item">2</span><span class="level-item">PyTorch Leaf Tensor</span></span></a></li><li><a class="level is-mobile" href="#Example"><span class="level-left"><span class="level-item">3</span><span class="level-item">Example</span></span></a></li><li><a class="level is-mobile" href="#FAQ"><span class="level-left"><span class="level-item">4</span><span class="level-item">FAQ</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Why-grad-is-not-populated-for-a-tensor-that-requires-grad-but-is-not-a-leaf-node"><span class="level-left"><span class="level-item">4.1</span><span class="level-item">Why grad is not populated for a tensor that requires grad but is not a leaf node?</span></span></a></li></ul></li><li><a class="level is-mobile" href="#References"><span class="level-left"><span class="level-item">5</span><span class="level-item">References</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget"><div class="g-ads-x"><div class="card-content"><div class="menu"><h3 class="menu-label">Advertisement</h3></div><br><center><script async type="text/javascript" src="//cdn.carbonads.com/carbon.js?serve=CWYDCK3L&amp;placement=leimaogithubio" id="_carbonads_js"></script></center></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/images/favicon/android-chrome-512x512.png" alt="Lei Mao&#039;s Log Book" height="28"></a><p class="is-size-7"><span>&copy; 2017-2024 Lei Mao</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Site UV: <span id="busuanzi_value_site_uv"><i class="fa fa-spinner fa-spin"></i></span></span> <span id="busuanzi_container_site_pv">Site PV: <span id="busuanzi_value_site_pv"><i class="fa fa-spinner fa-spin"></i></span></span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="GitHub" href="https://github.com/leimao"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/javascript" id="MathJax-script" async>MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      },
      chtml: {
        matchFontHeight: false
      }
    };</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js"></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><script src="/js/night.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>