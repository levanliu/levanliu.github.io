<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="twitter:image:src" content="https://leimao.github.io/images/favicon/android-chrome-512x512.png"><meta name="referrer" content="no-referrer-when-downgrade"><title>Maximum Likelihood Estimation of N-Gram Model Parameters - Lei Mao&#039;s Log Book</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#3273dc"><meta name="application-name" content="Lei Mao&#039;s Log Book"><meta name="msapplication-TileImage" content="/images/favicon/android-chrome-192x192.png"><meta name="msapplication-TileColor" content="#3273dc"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Lei Mao&#039;s Log Book"><meta name="apple-mobile-web-app-status-bar-style" content="default"><link rel="apple-touch-icon" sizes="192x192" href="/images/favicon/android-chrome-192x192.png"><link rel="apple-touch-icon" sizes="512x512" href="/images/favicon/android-chrome-512x512.png"><link rel="apple-touch-icon" sizes="180x180" href="/images/favicon/apple-touch-icon.png"><link rel="apple-touch-icon" sizes="16x16" href="/images/favicon/favicon-16x16.png"><link rel="apple-touch-icon" sizes="32x32" href="/images/favicon/favicon-32x32.png"><meta name="description" content="Mathematical Proof of the Maximum Likelihood Estimation of N-Gram Model Parameters"><meta property="og:type" content="blog"><meta property="og:title" content="Maximum Likelihood Estimation of N-Gram Model Parameters"><meta property="og:url" content="https://leimao.github.io/blog/Maximum-Likelihood-Estimation-Ngram/"><meta property="og:site_name" content="Lei Mao&#039;s Log Book"><meta property="og:description" content="Mathematical Proof of the Maximum Likelihood Estimation of N-Gram Model Parameters"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://leimao.github.io/images/favicon/android-chrome-512x512.png"><meta property="article:published_time" content="2018-06-09T07:00:00.000Z"><meta property="article:modified_time" content="2018-06-09T07:00:00.000Z"><meta property="article:author" content="Lei Mao"><meta property="article:tag" content="Probability"><meta property="article:tag" content="Natural Language Processing"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://leimao.github.io/images/favicon/android-chrome-512x512.png"><meta property="twitter:creator" content="@matchaleimao"><meta property="twitter:site" content="Lei Mao&#039;s Log Book"><meta property="fb:admins" content="dukeleimao"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://leimao.github.io/blog/Maximum-Likelihood-Estimation-Ngram/"},"headline":"Maximum Likelihood Estimation of N-Gram Model Parameters","image":["https://leimao.github.io/images/favicon/android-chrome-512x512.png"],"datePublished":"2018-06-09T07:00:00.000Z","dateModified":"2018-06-09T07:00:00.000Z","author":{"@type":"Person","name":"Lei Mao"},"publisher":{"@type":"Organization","name":"Lei Mao's Log Book","logo":{"@type":"ImageObject","url":"https://leimao.github.io/images/favicon/android-chrome-512x512.png"}},"description":"Mathematical Proof of the Maximum Likelihood Estimation of N-Gram Model Parameters"}</script><link rel="canonical" href="https://leimao.github.io/blog/Maximum-Likelihood-Estimation-Ngram/"><link rel="alternate" href="/atom.xml" title="Lei Mao&#039;s Log Book" type="application/atom+xml"><link rel="icon" href="/images/favicon/favicon.ico"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons/css/academicons.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=PT+Sans+Narrow:wght@400;700&amp;family=PT+Serif"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=G-EJY6FXZBCB" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'G-EJY6FXZBCB');</script><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><script src="//m.servedby-buysellads.com/monetization.custom.js"></script><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/images/favicon/android-chrome-512x512.png" alt="Lei Mao&#039;s Log Book" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Lei Mao&#039;s Log Book</a><a class="navbar-item" href="/curriculum">Curriculum</a><a class="navbar-item" href="/blog">Blog</a><a class="navbar-item" href="/article">Articles</a><a class="navbar-item" href="/project">Projects</a><a class="navbar-item" href="/publication">Publications</a><a class="navbar-item" href="/reading">Readings</a><a class="navbar-item" href="/life">Life</a><a class="navbar-item" href="/essay">Essay</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/faq">FAQs</a></div><div class="navbar-end"><a class="navbar-item night" id="night-nav" title="Switch Color Scheme" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/leimao"><i class="fab fa-github"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="Gitter" href="https://gitter.im/leimao/community"><i class="fab fa-gitter"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><div class="card-content"><center><div class="bsa-standard" id="carbon-ad-01"></div><script>            (function() {             if (typeof _bsa !== 'undefined' && _bsa) {                 _bsa.init('custom', 'CWYD65QY', 'placement:leimaogithubio-standard', {                     target: '#carbon-ad-01',                     template: `             <a href='##link##' class='native-banner' style='background: ##backgroundColor##' rel='sponsored noopener' target='_blank' title='##company## — ##tagline##'>                 <img class='native-img' width='125' src='##logo##' />                 <div class='native-main'>                     <div class='native-details' style='                             color: ##textColor##;                             border-left: solid 1px ##textColor##;                         '>                         <span class='native-company'>Sponsored by ##company##</span>                         <span class='native-desc'>##description##</span>                     </div>                     <span class='native-cta' style='                             color: ##ctaTextColor##;                             background-color: ##ctaBackgroundColor##;                         '>##callToAction##</span>                 </div>             </a>             `,                 });                 }             })();         </script></center></div></div><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-3" style="font-family: 'PT Sans Narrow', sans-serif">Maximum Likelihood Estimation of N-Gram Model Parameters</h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left" style="margin-bottom: 0.50rem"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2018-06-09T07:00:00.000Z" title="2018-06-09T07:00:00.000Z">06-09-2018</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="2018-06-09T07:00:00.000Z" title="2018-06-09T07:00:00.000Z">06-09-2018</time></span><span class="level-item"><i class="far fa-folder-open has-text-grey"></i> <a class="link-muted" href="/blog/">blog</a></span><span class="level-item"><i class="far fa-clock"></i> 8 minutes read (About 1220 words)</span><span class="level-item" id="busuanzi_container_page_pv"><i class="far fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"><i class="fa fa-spinner fa-spin"></i></span>&nbsp;visits</span></div></div><div class="content" style="margin-top: 1.0rem"><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>A language model is a probability distribution over sequences of words, namely:</p>
<p>$$p(w_1, w_2, w_3, …, w_n)$$</p>
<p>According to the chain rule,</p>
<p>$$<br>  p(w_1, w_2, w_3, …, w_n) = p(w_1)p(w_2|w_1)p(w_3|w_2,w_1)…p(w_n|w_{n-1},w_{n-2},…,w_1)<br>$$</p>
<p>However, the parameters for this language model are $p(w_1)$, $p(w_2|w_1)$, …, $p(w_n|w_{n-1},…,w_1)$, which are usually too computationally expensive to calculate especially for the conditional probability with many conditioning words, even with a small dataset.</p>
<p>To approximate $p(w_1, w_2, w_3, …, w_n)$, we could use N-Gram models to approximate the language model, namely:</p>
<h3 id="N-Gram-Model"><a href="#N-Gram-Model" class="headerlink" title="N-Gram Model"></a>N-Gram Model</h3><p>$$<br>p(w_1, w_2, w_3, …, w_n) \approx p(w_1)p(w_2|w_1)p(w_3|w_2,w_1)…p(w_n|w_{n-1},w_{n-2},…,w_{n-N})<br>$$</p>
<p>In particular, we usually use unigram model, bigram model and trigram model in language modelings.</p>
<h3 id="Unigram-Model"><a href="#Unigram-Model" class="headerlink" title="Unigram Model"></a>Unigram Model</h3><p>$$<br>p(w_1, w_2, w_3, …, w_n) \approx p(w_1)p(w_2)p(w_3)…p(w_n)<br>$$</p>
<h3 id="Bigram-Model"><a href="#Bigram-Model" class="headerlink" title="Bigram Model"></a>Bigram Model</h3><p>$$<br>p(w_1, w_2, w_3, …, w_n) \approx p(w_1)p(w_2|w_1)p(w_3|w_2)…p(w_n|w_{n-1})<br>$$</p>
<h3 id="Trigram-Model"><a href="#Trigram-Model" class="headerlink" title="Trigram Model"></a>Trigram Model</h3><p>$$<br>p(w_1, w_2, w_3, …, w_n) \approx p(w_1)p(w_2|w_1)p(w_3|w_2,w_1)…p(w_n|w_{n-1},w_{n-2})<br>$$</p>
<p>With the N-Gram model approximations, calculating $p(w_n|w_{n-1},w_{n-2},…,w_{n-N})$ is usually not too computationally expensive.</p>
<h2 id="Maximum-Likelihood-Estimation-of-N-Gram-Model-Parameters"><a href="#Maximum-Likelihood-Estimation-of-N-Gram-Model-Parameters" class="headerlink" title="Maximum Likelihood Estimation of N-Gram Model Parameters"></a>Maximum Likelihood Estimation of N-Gram Model Parameters</h2><p>To estimate $p(w_n|w_{n-1},w_{n-2},…,w_{n-N})$, an intuitive way is to do  maximum likelihood estimation (MLE).</p>
<p>Maximum likelihood estimation estimates the model parameters such that the probability is maximized.</p>
<p>In our case, the parameters are $p(w_n|w_{n-1},w_{n-2},…,w_{n-N})$, and the probability we maximizes is $p(w_1)p(w_2|w_1)p(w_3|w_2,w_1)…p(w_n|w_{n-1},w_{n-2},…,w_{n-N})$</p>
<p>In practice, we simply count the occurrence of word patterns to calculate the maximum likelihood estimation of $p(w_n|w_{n-1},w_{n-2},…,w_{n-N})$.</p>
<h3 id="Unigram-Model-1"><a href="#Unigram-Model-1" class="headerlink" title="Unigram Model"></a>Unigram Model</h3><p>$$p(w_i) = \frac{c(w_i)}{\sum_{w}^{} c(w)}$$</p>
<h3 id="Bigram-Model-1"><a href="#Bigram-Model-1" class="headerlink" title="Bigram Model"></a>Bigram Model</h3><p>$$p(w_i|w_{i-1}) = \frac{c(w_{i-1},w_i)}{\sum_{w}^{} c(w_{i-1},w)}$$</p>
<h3 id="Trigram-Model-1"><a href="#Trigram-Model-1" class="headerlink" title="Trigram Model"></a>Trigram Model</h3><p>$$p(w_i|w_{i-1},w_{i-2}) = \frac{c(w_{i-2},w_{i-1},w_i)}{\sum_{w}^{} c(w_{i-2},w_{i-1},w)}$$</p>
<p>Now the question becomes why these formulas are the maximum likelihood estimations. Most of the books and online tutorials only give these formulas without showing formal mathematical proof. </p>
<p>Here I am going to rigorously show that these are actually the formulas of maximum likelihood estimation.</p>
<h2 id="Mathematical-Derivation-of-Maximum-Likelihood-Estimation-of-N-Gram-Model-Parameters"><a href="#Mathematical-Derivation-of-Maximum-Likelihood-Estimation-of-N-Gram-Model-Parameters" class="headerlink" title="Mathematical Derivation of Maximum Likelihood Estimation of N-Gram Model Parameters"></a>Mathematical Derivation of Maximum Likelihood Estimation of N-Gram Model Parameters</h2><h3 id="Unigram-Model-2"><a href="#Unigram-Model-2" class="headerlink" title="Unigram Model"></a>Unigram Model</h3><p>Let us warm up with unigram model. </p>
<p>We have a collection of unique words, $w_1, w_2, …, w_n$. </p>
<p>For any given sequence of words $\mathbf{w}$ of length $N$ ($\mathbf{w} = (w_1, w_2, w_1, w_5, w_7, w_2)$ for example), we have</p>
<p>$$<br>\begin{aligned}<br>p(\mathbf{w})<br>&amp; = p(w_1)^{c(w_1)} p(w_2)^{c(w_2)} p(w_3)^{c(w_3)}…p(w_n)^{c(w_n)}\\<br>&amp; = \prod_{i=1}^{n}p(w_i)^{c(w_i)}<br>\end{aligned}<br>$$</p>
<p>where $c(w_i)$ is the count of word $w_i$ in the sentence.</p>
<p>We take the log of $p(\mathbf{w})$, we then have:</p>
<p>$$<br>\begin{aligned}<br>\log{p(\mathbf{w})}<br>&amp; = c(w_1)\log{p(w_1)} + c(w_2)\log{p(w_2)} + c(w_3)\log{p(w_3)} + … + c(w_n)\log{p(w_n)}\\<br>&amp; = \sum_{i=1}^{n}c(w_i)\log{p(w_i)}<br>\end{aligned}<br>$$</p>
<p>To maximize $p(\mathbf{w})$, equivalently we have the following optimization problem:</p>
<p>Maximize $\log{p(\mathbf{w})}$, subject to $\forall i \in [1 \dotsc N]$, $\sum_{i =  1}^{n} p(w_i) = 1$.</p>
<p>Equivalently, we introduce auxilliary optimization function using Lagrange multiplier ($\sum_{i=1}^{n}p(w_i)-1 = 0$):</p>
<p>$$<br>\mathcal{L} = \sum_{i=1}^{n}c(w_i)\log{p(w_i)} + \lambda(\sum_{i=1}^{n}p(w_i)-1)<br>$$</p>
<p>For any $p(w_j)$, we take the derivatives of $\mathcal{L}$ respective to $p(w_j)$:</p>
<p>$$\frac{\partial \mathcal{L}}{\partial p(w_j)} = \frac{c(w_j)}{p(w_j)} + \lambda = 0$$</p>
<p>$$p(w_j) = -\frac{c(w_j)}{\lambda}$$</p>
<p>Because $\sum_{i=1}^{n}p(w_i) = 1$, we have:</p>
<p>$$\sum_{i=1}^{n}p(w_i) = \sum_{i=1}^{n} -\frac{c(w_i)}{\lambda} = \frac{\sum_{i=1}^{n} c(w_i)}{-\lambda} = 1$$</p>
<p>$$\lambda = - \sum_{i=1}^{n} c(w_i)$$</p>
<p>Because $p(w_j) = -c(w_j)/{\lambda}$, therefore</p>
<p>$$p(w_j) = \frac{c(w_j)}{\sum_{i=1}^{n} c(w_i)}$$</p>
<p>This concludes the proof.</p>
<h3 id="Bigram-Model-2"><a href="#Bigram-Model-2" class="headerlink" title="Bigram Model"></a>Bigram Model</h3><p>Now let us move on to bigram model to see what is different.</p>
<p>We have a collection of unique words, $w_1, w_2, …, w_n$. </p>
<p>For the conditional probabilities, we have $n \times n$ possibilities.</p>
<p>For any given sequence of words $\mathbf{w}$ of length $N$ ($\mathbf{w} = (w_1, w_2, w_1, w_5, w_7, w_2)$ for example), we have</p>
<p>$$<br>\begin{aligned}<br>p(\mathbf{w})<br>&amp; = \prod_{i=1}^{n} p(w_i)^{s(w_i)} \prod_{i=1}^{n} \prod_{j=1}^{n} p(w_j|w_i)^{c(w_i, w_j)}<br>\end{aligned}<br>$$</p>
<p>where $c(w_i, w_j)$ is the count of word sequence $w_i, w_j$ in the sentence and </p>
<p>$$<br>s(w_i) = \begin{cases}<br>    1, &amp; \text{if $w_i$ is the first word}\\<br>    0, &amp; \text{otherwise}<br>    \end{cases}<br>$$</p>
<p>We take the log of $p(\mathbf{w})$, we then have:</p>
<p>$$<br>\begin{aligned}<br>\log{p(\mathbf{w})}<br>&amp; = \sum_{i=1}^{n}s(w_i)\log{p(w_i)} + \sum_{i=1}^{n}\sum_{j=1}^{n}c(w_i,w_j)\log{p(w_j|w_i)}<br>\end{aligned}<br>$$</p>
<p>To maximize $p(\mathbf{w})$, equivalently we have the following optimization problem:</p>
<p>Maximize $\log{p(\mathbf{w})}$, subject to $\forall i \in [1 \dotsc N]$, $\sum_{j =  1}^{n} p(w_j|w_i) = 1$.</p>
<p>Equivalently, we introduce auxiliary optimization function using Lagrange multiplier ($\sum_{j =  1}^{n} p(w_j|w_i)-1 = 0$):</p>
<p>$$<br>\mathcal{L} = \sum_{i=1}^{n}s(w_i)\log{p(w_i)} + \sum_{i=1}^{n}\sum_{j=1}^{n}c(w_i,w_j)\log{p(w_j|w_i)} +  \sum_{i=1}^{n} \lambda_i \bigg( \big(\sum_{j = 1}^{n} p(w_j|w_i) \big) - 1 \bigg)<br>$$</p>
<p>For any $p(w_k|w_i)$, we take the derivatives of $\mathcal{L}$ respective to $p(w_k|w_i)$:</p>
<p>$$\frac{\partial \mathcal{L}}{\partial p(w_k|w_i)} = \frac{c(w_i, w_k)}{p(w_k|w_i)} + \lambda_i = 0$$</p>
<p>$$p(w_k|w_i) = -\frac{c(w_i, w_k)}{\lambda_i}$$</p>
<p>Because $\sum_{j =  1}^{n} p(w_j|w_i) = 1$, we have:</p>
<p>$$\sum_{j =  1}^{n} p(w_j|w_i) = \sum_{j =  1}^{n} -\frac{c(w_i, w_j)}{\lambda_i} = \frac{\sum_{j =  1}^{n} c(w_i, w_j)}{-\lambda_i} = 1$$</p>
<p>$$\lambda_i = -\sum_{j =  1}^{n} c(w_i, w_j)$$</p>
<p>Because $p(w_k|w_i) = -c(w_i, w_k)/\lambda_i$, therefore</p>
<p>$$p(w_k|w_i) = \frac{c(w_i, w_k)}{\sum_{j =  1}^{n} c(w_i, w_j)}$$</p>
<p>This concludes the proof.</p>
<h3 id="N-Gram-Model-1"><a href="#N-Gram-Model-1" class="headerlink" title="N-Gram Model"></a>N-Gram Model</h3><p>Without losing generality, the maximum likelihood estimation of n-gram model parameters could also be proven in the same way.</p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Mathematics is important for (statistical) machine learning.</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>Maximum Likelihood Estimation of N-Gram Model Parameters</p><p><a href="https://leimao.github.io/blog/Maximum-Likelihood-Estimation-Ngram/">https://leimao.github.io/blog/Maximum-Likelihood-Estimation-Ngram/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Lei Mao</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>06-09-2018</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>06-09-2018</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <div><a class="link-muted" rel="tag" href="/tags/Probability/">Probability,</a> </div><div><a class="link-muted" rel="tag" href="/tags/Natural-Language-Processing/">Natural Language Processing </a> </div></div></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=61b5930d440224001908310c&amp;product=inline-share-buttons" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered has-text-weight-normal">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button donate" data-type="paypal" onclick="document.getElementById(&#039;paypal-donate-form&#039;).submit()"><span class="icon is-small"><i class="fab fa-paypal"></i></span><span>Paypal</span></a><form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_blank" rel="noopener" id="paypal-donate-form"><input type="hidden" name="cmd" value="_donations"><input type="hidden" name="business" value="SSVSLEH4X85LU"><input type="hidden" name="currency_code" value="USD"></form><a class="button donate" href="https://www.buymeacoffee.com/leimao" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>Buy me a coffee</span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/project/Image-Converter-CycleGAN/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">CycleGAN Image Converter</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/blog/Jupyter-Notebook-On-Docker/"><span class="level-item">Jupyter Notebook on Docker</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card" id="comment-card"><div class="card-content"><h3 class="title is-5">Comments</h3><div class="comment-block"><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://leimao.github.io/blog/Maximum-Likelihood-Estimation-Ngram/';
            this.page.identifier = '/blog/Maximum-Likelihood-Estimation-Ngram/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'leimao-github-io' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/author_images/Lei-Bio-Medium.jpg" alt="Lei Mao"></figure><p class="title is-size-4 is-block" style="line-height:inherit;margin-bottom:0.30rem;">Lei Mao</p><p class="is-block" style="white-space: pre-line; font-style: italic; margin-bottom: 0.50rem; font-size: 0.8em">Artificial Intelligence
Machine Learning
Computer Science
</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Santa Clara, California</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">733</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">7</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">453</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/leimao" target="_blank" rel="noopener"><i class="fab fa-github"></i>  Follow</a> <a class="level-item button is-primary is-rounded" href="https://github.com/sponsors/leimao" target="_blank" rel="noopener"><i class="fas fa-heart"></i>  Sponsor</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/leimao"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/matchaleimao"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="LinkedIn" href="https://www.linkedin.com/in/lei-mao/"><i class="fab fa-linkedin"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="mailto:dukeleimao@gmail.com"><i class="fas fa-envelope-square"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="G.Scholar" href="https://scholar.google.com/citations?user=R2VUf7YAAAAJ"><i class="ai ai-google-scholar-square"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Introduction"><span class="level-left"><span class="level-item">1</span><span class="level-item">Introduction</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#N-Gram-Model"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">N-Gram Model</span></span></a></li><li><a class="level is-mobile" href="#Unigram-Model"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">Unigram Model</span></span></a></li><li><a class="level is-mobile" href="#Bigram-Model"><span class="level-left"><span class="level-item">1.3</span><span class="level-item">Bigram Model</span></span></a></li><li><a class="level is-mobile" href="#Trigram-Model"><span class="level-left"><span class="level-item">1.4</span><span class="level-item">Trigram Model</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Maximum-Likelihood-Estimation-of-N-Gram-Model-Parameters"><span class="level-left"><span class="level-item">2</span><span class="level-item">Maximum Likelihood Estimation of N-Gram Model Parameters</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Unigram-Model-1"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">Unigram Model</span></span></a></li><li><a class="level is-mobile" href="#Bigram-Model-1"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">Bigram Model</span></span></a></li><li><a class="level is-mobile" href="#Trigram-Model-1"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">Trigram Model</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Mathematical-Derivation-of-Maximum-Likelihood-Estimation-of-N-Gram-Model-Parameters"><span class="level-left"><span class="level-item">3</span><span class="level-item">Mathematical Derivation of Maximum Likelihood Estimation of N-Gram Model Parameters</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Unigram-Model-2"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">Unigram Model</span></span></a></li><li><a class="level is-mobile" href="#Bigram-Model-2"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">Bigram Model</span></span></a></li><li><a class="level is-mobile" href="#N-Gram-Model-1"><span class="level-left"><span class="level-item">3.3</span><span class="level-item">N-Gram Model</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Conclusion"><span class="level-left"><span class="level-item">4</span><span class="level-item">Conclusion</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget"><div class="g-ads-x"><div class="card-content"><div class="menu"><h3 class="menu-label">Advertisement</h3></div><br><center><script async type="text/javascript" src="//cdn.carbonads.com/carbon.js?serve=CWYDCK3L&amp;placement=leimaogithubio" id="_carbonads_js"></script></center></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/images/favicon/android-chrome-512x512.png" alt="Lei Mao&#039;s Log Book" height="28"></a><p class="is-size-7"><span>&copy; 2017-2024 Lei Mao</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Site UV: <span id="busuanzi_value_site_uv"><i class="fa fa-spinner fa-spin"></i></span></span> <span id="busuanzi_container_site_pv">Site PV: <span id="busuanzi_value_site_pv"><i class="fa fa-spinner fa-spin"></i></span></span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="GitHub" href="https://github.com/leimao"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/javascript" id="MathJax-script" async>MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      },
      chtml: {
        matchFontHeight: false
      }
    };</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js"></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><script src="/js/night.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>