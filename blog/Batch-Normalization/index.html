<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="twitter:image:src" content="https://levanliu.github.io/images/favicon/android-chrome-512x512.png"><meta name="referrer" content="no-referrer-when-downgrade"><title>Batch Normalization Explained - Lei Mao&#039;s Log Book</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#3273dc"><meta name="application-name" content="Lei Mao&#039;s Log Book"><meta name="msapplication-TileImage" content="/images/favicon/android-chrome-192x192.png"><meta name="msapplication-TileColor" content="#3273dc"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Lei Mao&#039;s Log Book"><meta name="apple-mobile-web-app-status-bar-style" content="default"><link rel="apple-touch-icon" sizes="192x192" href="/images/favicon/android-chrome-192x192.png"><link rel="apple-touch-icon" sizes="512x512" href="/images/favicon/android-chrome-512x512.png"><link rel="apple-touch-icon" sizes="180x180" href="/images/favicon/apple-touch-icon.png"><link rel="apple-touch-icon" sizes="16x16" href="/images/favicon/favicon-16x16.png"><link rel="apple-touch-icon" sizes="32x32" href="/images/favicon/favicon-32x32.png"><meta name="description" content="Fill More Holes in Deep Learning"><meta property="og:type" content="blog"><meta property="og:title" content="Batch Normalization Explained"><meta property="og:url" content="https://levanliu.github.io/blog/Batch-Normalization/"><meta property="og:site_name" content="Lei Mao&#039;s Log Book"><meta property="og:description" content="Fill More Holes in Deep Learning"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://levanliu.github.io/images/favicon/android-chrome-512x512.png"><meta property="article:published_time" content="2018-09-07T07:00:00.000Z"><meta property="article:modified_time" content="2019-05-31T07:00:00.000Z"><meta property="article:author" content="Lei Mao"><meta property="article:tag" content="Deep Learning"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://levanliu.github.io/images/favicon/android-chrome-512x512.png"><meta property="twitter:creator" content="@matchalevanliu"><meta property="twitter:site" content="Lei Mao&#039;s Log Book"><meta property="fb:admins" content="dukelevanliu"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://levanliu.github.io/blog/Batch-Normalization/"},"headline":"Batch Normalization Explained","image":["https://levanliu.github.io/images/favicon/android-chrome-512x512.png"],"datePublished":"2018-09-07T07:00:00.000Z","dateModified":"2019-05-31T07:00:00.000Z","author":{"@type":"Person","name":"Lei Mao"},"publisher":{"@type":"Organization","name":"Lei Mao's Log Book","logo":{"@type":"ImageObject","url":"https://levanliu.github.io/images/favicon/android-chrome-512x512.png"}},"description":"Fill More Holes in Deep Learning"}</script><link rel="canonical" href="https://levanliu.github.io/blog/Batch-Normalization/"><link rel="alternate" href="/atom.xml" title="Lei Mao&#039;s Log Book" type="application/atom+xml"><link rel="icon" href="/images/favicon/favicon.ico"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons/css/academicons.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=PT+Sans+Narrow:wght@400;700&amp;family=PT+Serif"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=G-EJY6FXZBCB" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'G-EJY6FXZBCB');</script><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><script src="//m.servedby-buysellads.com/monetization.custom.js"></script><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/images/favicon/android-chrome-512x512.png" alt="Lei Mao&#039;s Log Book" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Lei Mao&#039;s Log Book</a><a class="navbar-item" href="/curriculum">Curriculum</a><a class="navbar-item" href="/blog">Blog</a><a class="navbar-item" href="/article">Articles</a><a class="navbar-item" href="/project">Projects</a><a class="navbar-item" href="/publication">Publications</a><a class="navbar-item" href="/reading">Readings</a><a class="navbar-item" href="/life">Life</a><a class="navbar-item" href="/essay">Essay</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/faq">FAQs</a></div><div class="navbar-end"><a class="navbar-item night" id="night-nav" title="Switch Color Scheme" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/levanliu"><i class="fab fa-github"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="Gitter" href="https://gitter.im/levanliu/community"><i class="fab fa-gitter"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><div class="card-content"><center><div class="bsa-standard" id="carbon-ad-01"></div><script>            (function() {             if (typeof _bsa !== 'undefined' && _bsa) {                 _bsa.init('custom', 'CWYD65QY', 'placement:levanliugithubio-standard', {                     target: '#carbon-ad-01',                     template: `             <a href='##link##' class='native-banner' style='background: ##backgroundColor##' rel='sponsored noopener' target='_blank' title='##company## — ##tagline##'>                 <img class='native-img' width='125' src='##logo##' />                 <div class='native-main'>                     <div class='native-details' style='                             color: ##textColor##;                             border-left: solid 1px ##textColor##;                         '>                         <span class='native-company'>Sponsored by ##company##</span>                         <span class='native-desc'>##description##</span>                     </div>                     <span class='native-cta' style='                             color: ##ctaTextColor##;                             background-color: ##ctaBackgroundColor##;                         '>##callToAction##</span>                 </div>             </a>             `,                 });                 }             })();         </script></center></div></div><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-3" style="font-family: 'PT Sans Narrow', sans-serif">Batch Normalization Explained</h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left" style="margin-bottom: 0.50rem"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2018-09-07T07:00:00.000Z" title="2018-09-07T07:00:00.000Z">09-07-2018</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="2019-05-31T07:00:00.000Z" title="2019-05-31T07:00:00.000Z">05-31-2019</time></span><span class="level-item"><i class="far fa-folder-open has-text-grey"></i> <a class="link-muted" href="/blog/">blog</a></span><span class="level-item"><i class="far fa-clock"></i> 6 minutes read (About 961 words)</span><span class="level-item" id="busuanzi_container_page_pv"><i class="far fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"><i class="fa fa-spinner fa-spin"></i></span>&nbsp;visits</span></div></div><div class="content" style="margin-top: 1.0rem"><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Recently I was working on a collaborative deep learning project trying to reproduce a model from the publication, but I found the model was overfit significantly. My dear colleague examined my code and pointed out that there might be some problems in my Tensorflow batch normalization implementation. After checking the possible correct implementation, I realized that probably I did not fully understand batch normalization. In this blog post, I am going to review batch normalization again on its mathematical definition and intuitions.</p>
<h2 id="Motivation-of-Batch-Normalization"><a href="#Motivation-of-Batch-Normalization" class="headerlink" title="Motivation of Batch Normalization"></a>Motivation of Batch Normalization</h2><p>I am not going to explain why batch normalization works well in real practice, since Andrew Ng has a very good <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=nUUqwaxLnWs">video</a> explaining that.</p>
<h2 id="Mathematical-Definition"><a href="#Mathematical-Definition" class="headerlink" title="Mathematical Definition"></a>Mathematical Definition</h2><h3 id="Training-Phase"><a href="#Training-Phase" class="headerlink" title="Training Phase"></a>Training Phase</h3><p>Given inputs $x$ over a minibatch of size $m$, $B = \{x_1, x_2, …, x_m\}$, by applying transformation of your inputs using some learned parameters $\gamma$ and $\beta$, the outputs could be expressed as $B’ = \{y_1, y_2, …, y_m\}$, where $y_i = {\text{BN}}_{\gamma, \beta} (x_i)$.</p>
<p>More concretely, we first calculate the mean and the variance of the samples from the minibatch.</p>
<p>$$<br>\begin{gather}<br>\mu_B = \frac{1}{m} \sum_{i=1}^{m} x_i \\<br>\sigma_B^2 = \frac{1}{m} \sum_{i=1}^{m} (x_i - \mu_B)^2 \\<br>\end{gather}<br>$$</p>
<p>Then we normalize the samples to zero means and unit variance. $\epsilon$ is for numerical stability in case the denominator becomes zero by chance.</p>
<p>$$<br>\hat{x}_{i} = \frac{x_i-\mu_B}{\sqrt{\sigma_B^2 + \epsilon}}<br>$$</p>
<p>Finally, a little bit surprising, there is a scaling and shifting step. $\gamma$ and $\beta$ are learnable parameters.</p>
<p>$$<br>y_i = \gamma \hat{x}_{i} + \beta \equiv {\text{BN}}_{\gamma, \beta} (x_i)<br>$$</p>
<h3 id="Test-Phase"><a href="#Test-Phase" class="headerlink" title="Test Phase"></a>Test Phase</h3><p>During the test phase, specifically when you only have one test sample, doing batch normalization as the one in the training phase does not make sense, because your outputs at each layer of the network will be exactly zero. To overcome this, people invented “running mean” and “running variance”, which are updated in real-time during training.</p>
<p>More concretely, at training time step t, the running mean $\mu_B’[t]$ and running variance $\sigma_B^{\prime 2}[t]$ are calculated as follows:</p>
<p>$$<br>\begin{gather}<br>\mu_B’[t] = \mu_B’[t] \times \text{momentum} + \mu_B[t] \times (1 - \text{momentum})\\<br>\sigma_B^{\prime 2}[t] = \sigma_B^{\prime 2}[t] \times \text{momentum} + \sigma_B^2[t] \times (1 - \text{momentum}) \\<br>\end{gather}<br>$$</p>
<p>Here momentum is sometimes also called decay.</p>
<p>The “running mean” and “running variance” were computed during training and would be used during inference.</p>
<h2 id="Caveats"><a href="#Caveats" class="headerlink" title="Caveats"></a>Caveats</h2><h3 id="Value-of-Momentum"><a href="#Value-of-Momentum" class="headerlink" title="Value of Momentum"></a>Value of Momentum</h3><p>Surprisingly, momentum is a very important parameter for model validation performance. In TensorFlow, it suggests how to set momentum correctly.</p>
<p>decay: Decay for the moving average. Reasonable values for decay are close to 1.0, typically in the multiple-nines range: 0.999, 0.99, 0.9, etc. Lower decay value (recommend trying decay=0.9) if the model experiences reasonably good training performance but poor validation and/or test performance. Try zero_debias_moving_mean=True for improved stability.</p>
<p>Intuitively, when momentum = 0, the running means and variances are always the means and variance of the last minibatch. This running means and variance could be highly biased and thus the training performance and validation performance differ significantly. When momentum = 1.0, the running means and variances are always the means and variance of the first minibatch, which could also be highly biased. So the momentum value should not be extremely close to 0 or 1.0. In addition, because we want to “average” over as many samples as possible and the samples in the past mini-batches are important which should be given more weights, the momentum value should be a large number close to 1.0. The momentum could be thought of as a weight factor for the past and the present information! Therefore, taken together, a value of multiple nines are recommended for momentum.</p>
<h3 id="Specify-Training-Mode-and-Test-Mode"><a href="#Specify-Training-Mode-and-Test-Mode" class="headerlink" title="Specify Training Mode and Test Mode"></a>Specify Training Mode and Test Mode</h3><p>In TensorFlow, you will have to specify training mode and test mode when you are running your model in different stages. </p>
<p>There is also a very special setting in TensorFlow if you want to train a model that has a batch norm layer. Unfortunately, for some of my previous codes, I did not have these settings, which means that during the test stage, the samples were not probably normalized “correctly” as expected. Zero will be output from the batch norm layer if test samples are tested one by one, which will significantly affect the testing performance!</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x_norm = tf.layers.batch_normalization(x, training=training)</span><br><span class="line"></span><br><span class="line"># ...</span><br><span class="line"></span><br><span class="line">update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)</span><br><span class="line">with tf.control_dependencies(update_ops):</span><br><span class="line">    train_op = optimizer.minimize(loss)</span><br></pre></td></tr></table></figure>

<h3 id="Batch-Normalization-in-Convolutional-Neural-Network"><a href="#Batch-Normalization-in-Convolutional-Neural-Network" class="headerlink" title="Batch Normalization in Convolutional Neural Network"></a>Batch Normalization in Convolutional Neural Network</h3><p>If batch normalization is working on the outputs from a convolution layer, the math has to be modified slightly since it does not make sense to calculate the mean and variance for every single pixel and do the normalization for every single pixel. </p>
<p>Assume the input tensor has shape $[m, H, W, C]$, for each channel $c \in \{1,2, \cdots, C\}$</p>
<p>$$<br>\begin{gather}<br>\mu_{B,c} = \frac{1}{mHW} \sum_{i=1}^{m} \sum_{j=1}^{H} \sum_{k=1}^{W} x_{i,j,k,c} \\<br>\sigma_{B,c}^2 = \frac{1}{mHW} \sum_{i=1}^{m} \sum_{j=1}^{H} \sum_{k=1}^{W} (x_{i,j,k,c} - \mu_{B,c})^2 \\<br>\end{gather}<br>$$</p>
<p>$$<br>\hat{x}_{i,j,k,c} = \frac{x_{i,j,k,c}-\mu_{B,c}}{\sqrt{\sigma_{B,c}^2 + \epsilon}}<br>$$</p>
<p>Specifically for each channel, we have learnable parameters $\gamma_c$ and $\beta_c$, such that</p>
<p>$$<br>y_{i,:,:,c} = \gamma_c \hat{x}_{i,:,:,c} + \beta_c \equiv {\text{BN}}_{\gamma_c, \beta_c} (x_{i,:,:,c})<br>$$</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1502.03167">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a></li>
<li><a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization">Batch Normalization TensorFlow Implementation</a></li>
</ul>
</div><div class="article-licensing box"><div class="licensing-title"><p>Batch Normalization Explained</p><p><a href="https://levanliu.github.io/blog/Batch-Normalization/">https://levanliu.github.io/blog/Batch-Normalization/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Lei Mao</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>09-07-2018</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>05-31-2019</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <div><a class="link-muted" rel="tag" href="/tags/Deep-Learning/">Deep Learning </a> </div></div></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=61b5930d440224001908310c&amp;product=inline-share-buttons" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered has-text-weight-normal">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button donate" data-type="paypal" onclick="document.getElementById(&#039;paypal-donate-form&#039;).submit()"><span class="icon is-small"><i class="fab fa-paypal"></i></span><span>Paypal</span></a><form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_blank" rel="noopener" id="paypal-donate-form"><input type="hidden" name="cmd" value="_donations"><input type="hidden" name="business" value="SSVSLEH4X85LU"><input type="hidden" name="currency_code" value="USD"></form><a class="button donate" href="https://www.buymeacoffee.com/levanliu" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>Buy me a coffee</span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/project/DeepLab-V3/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Semantic Segmentation Using DeepLab V3</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/blog/TensorFlow-Dataset-API/"><span class="level-item">Guide to TensorFlow Dataset API</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card" id="comment-card"><div class="card-content"><h3 class="title is-5">Comments</h3><div class="comment-block"><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://levanliu.github.io/blog/Batch-Normalization/';
            this.page.identifier = '/blog/Batch-Normalization/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'levanliu-github-io' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/author_images/Lei-Bio-Medium.jpg" alt="Lei Mao"></figure><p class="title is-size-4 is-block" style="line-height:inherit;margin-bottom:0.30rem;">Lei Mao</p><p class="is-block" style="white-space: pre-line; font-style: italic; margin-bottom: 0.50rem; font-size: 0.8em">Artificial Intelligence
Machine Learning
Computer Science
</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Santa Clara, California</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">733</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">7</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">453</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/levanliu" target="_blank" rel="noopener"><i class="fab fa-github"></i>  Follow</a> <a class="level-item button is-primary is-rounded" href="https://github.com/sponsors/levanliu" target="_blank" rel="noopener"><i class="fas fa-heart"></i>  Sponsor</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/levanliu"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/matchalevanliu"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="LinkedIn" href="https://www.linkedin.com/in/lei-mao/"><i class="fab fa-linkedin"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="mailto:dukelevanliu@gmail.com"><i class="fas fa-envelope-square"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="G.Scholar" href="https://scholar.google.com/citations?user=R2VUf7YAAAAJ"><i class="ai ai-google-scholar-square"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Introduction"><span class="level-left"><span class="level-item">1</span><span class="level-item">Introduction</span></span></a></li><li><a class="level is-mobile" href="#Motivation-of-Batch-Normalization"><span class="level-left"><span class="level-item">2</span><span class="level-item">Motivation of Batch Normalization</span></span></a></li><li><a class="level is-mobile" href="#Mathematical-Definition"><span class="level-left"><span class="level-item">3</span><span class="level-item">Mathematical Definition</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Training-Phase"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">Training Phase</span></span></a></li><li><a class="level is-mobile" href="#Test-Phase"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">Test Phase</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Caveats"><span class="level-left"><span class="level-item">4</span><span class="level-item">Caveats</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Value-of-Momentum"><span class="level-left"><span class="level-item">4.1</span><span class="level-item">Value of Momentum</span></span></a></li><li><a class="level is-mobile" href="#Specify-Training-Mode-and-Test-Mode"><span class="level-left"><span class="level-item">4.2</span><span class="level-item">Specify Training Mode and Test Mode</span></span></a></li><li><a class="level is-mobile" href="#Batch-Normalization-in-Convolutional-Neural-Network"><span class="level-left"><span class="level-item">4.3</span><span class="level-item">Batch Normalization in Convolutional Neural Network</span></span></a></li></ul></li><li><a class="level is-mobile" href="#References"><span class="level-left"><span class="level-item">5</span><span class="level-item">References</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget"><div class="g-ads-x"><div class="card-content"><div class="menu"><h3 class="menu-label">Advertisement</h3></div><br><center><script async type="text/javascript" src="//cdn.carbonads.com/carbon.js?serve=CWYDCK3L&amp;placement=levanliugithubio" id="_carbonads_js"></script></center></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/images/favicon/android-chrome-512x512.png" alt="Lei Mao&#039;s Log Book" height="28"></a><p class="is-size-7"><span>&copy; 2017-2024 Lei Mao</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Site UV: <span id="busuanzi_value_site_uv"><i class="fa fa-spinner fa-spin"></i></span></span> <span id="busuanzi_container_site_pv">Site PV: <span id="busuanzi_value_site_pv"><i class="fa fa-spinner fa-spin"></i></span></span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="GitHub" href="https://github.com/levanliu"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/javascript" id="MathJax-script" async>MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      },
      chtml: {
        matchFontHeight: false
      }
    };</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js"></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><script src="/js/night.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>